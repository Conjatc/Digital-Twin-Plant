{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8e98dd",
   "metadata": {},
   "source": [
    "\n",
    "# Sensor + Image Dual-Output Model (Keras/TensorFlow)\n",
    "\n",
    "This notebook builds a dual-input neural network that combines **sensor time-series snapshots** with **camera images** to predict two targets:\n",
    "\n",
    "- **img_output** (2 classes): `good_h` vs `bad_h` based on image labels\n",
    "- **cond_output** (5 classes): plant condition based on sensor JSON (`Healthy`, `Overwatered`, `Lightly underwatered`, `Shocked`, `Overdried`)\n",
    "\n",
    "It performs:\n",
    "- Load & parse sensor JSON (`sensor_log_new.json`) with timestamp normalization and numerical scaling (`StandardScaler`).\n",
    "- Load images from `AWSimages - labeled/`, parse filenames like `good_h.08-03_10-10.jpeg` to extract **day** and **time** and binary label (`good_h` / `bad_h`).\n",
    "- **Match each sensor datapoint** to the **nearest image on the same day** (in minutes). If a sensor datapoint has no same-day image, it is **kept** and its image is set to a **zero tensor**; its contribution to the `img_output` loss is **masked** via `sample_weight`.\n",
    "- Build a **dual-branch model**:\n",
    "  - **Image branch**: `MobileNetV2` (ImageNet weights, frozen, `pooling='avg'`) with light data augmentation.\n",
    "  - **Sensor branch**: `Dense(32, relu) → Dropout(0.3) → Dense(16, relu)`.\n",
    "  - Merge → `Dense(64, relu) → Dropout(0.4)` → two softmax heads: `img_output` (2) and `cond_output` (5).\n",
    "- Compile with `Adam(1e-3)` and `SparseCategoricalCrossentropy` for both outputs; metric: `accuracy`.\n",
    "- Chronological train/validation split (80/20) by sensor timestamp.\n",
    "- Early stopping on `val_cond_output_accuracy` with `patience=8`, restoring best weights.\n",
    "- Save trained model as **`sensor_image_model.h5`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0f96b",
   "metadata": {},
   "source": [
    "## 1) Environment & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91953396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "# !pip -q install tensorflow==2.15.* pandas scikit-learn pillow matplotlib\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Reproducibility\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9982f7dc",
   "metadata": {},
   "source": [
    "## 2) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbec4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths\n",
    "SENSOR_JSON_PATH = Path(\"sensor_log_new.json\")           # JSON file with sensor readings\n",
    "IMAGES_DIR = Path(\"AWSimages-labeled\")                 # Folder containing labeled images\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = (224, 224)\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# Training settings\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 8\n",
    "\n",
    "# Expected labels\n",
    "IMG_LABELS = [\"bad_h\", \"good_h\"]  # mapped to {bad_h:0, good_h:1}\n",
    "COND_LABELS_EXPECTED = [\"Healthy\", \"OverW\", \"SUnderW\", \"Shocked\", \"UnderW\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae80f58",
   "metadata": {},
   "source": [
    "## 3) Load Sensor JSON, Parse Timestamps, Scale Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77fb7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found unexpected condition labels: ['Lightly underwatered', 'Overdried', 'Overwatered']\n",
      "Condition labels mapping: {'Healthy': 0, 'Lightly underwatered': 1, 'OverW': 2, 'Overdried': 3, 'Overwatered': 4, 'SUnderW': 5, 'Shocked': 6, 'UnderW': 7}\n",
      "Loaded sensor rows: 552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>temp</th>\n",
       "      <th>moist</th>\n",
       "      <th>brightness</th>\n",
       "      <th>green</th>\n",
       "      <th>label</th>\n",
       "      <th>liveOnly</th>\n",
       "      <th>timestamp_dt</th>\n",
       "      <th>md_key</th>\n",
       "      <th>minute_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07-14 21:45</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>-1.213585</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-07-14 21:45:00</td>\n",
       "      <td>07-14</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07-15 05:45</td>\n",
       "      <td>-0.648987</td>\n",
       "      <td>-1.459932</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-07-15 05:45:00</td>\n",
       "      <td>07-15</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07-15 06:15</td>\n",
       "      <td>-0.769966</td>\n",
       "      <td>-0.720892</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-07-15 06:15:00</td>\n",
       "      <td>07-15</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-15 06:45</td>\n",
       "      <td>-0.769966</td>\n",
       "      <td>-1.172527</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-07-15 06:45:00</td>\n",
       "      <td>07-15</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07-15 07:15</td>\n",
       "      <td>-0.825804</td>\n",
       "      <td>-1.131470</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>0.042601</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-07-15 07:15:00</td>\n",
       "      <td>07-15</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp      temp     moist  brightness     green    label  liveOnly  \\\n",
       "0  07-14 21:45 -0.006861 -1.213585    0.042601  0.042601  Healthy       NaN   \n",
       "1  07-15 05:45 -0.648987 -1.459932    0.042601  0.042601  Healthy       NaN   \n",
       "2  07-15 06:15 -0.769966 -0.720892    0.042601  0.042601  Healthy       NaN   \n",
       "3  07-15 06:45 -0.769966 -1.172527    0.042601  0.042601  Healthy       NaN   \n",
       "4  07-15 07:15 -0.825804 -1.131470    0.042601  0.042601  Healthy       NaN   \n",
       "\n",
       "         timestamp_dt md_key  minute_of_day  \n",
       "0 1900-07-14 21:45:00  07-14           1305  \n",
       "1 1900-07-15 05:45:00  07-15            345  \n",
       "2 1900-07-15 06:15:00  07-15            375  \n",
       "3 1900-07-15 06:45:00  07-15            405  \n",
       "4 1900-07-15 07:15:00  07-15            435  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "assert SENSOR_JSON_PATH.exists(), f\"Missing {SENSOR_JSON_PATH}. Place it next to this notebook.\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_json(SENSOR_JSON_PATH)\n",
    "\n",
    "# Basic schema checks\n",
    "required_cols = [\"timestamp\", \"temp\", \"moist\", \"brightness\", \"green\", \"label\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "assert not missing, f\"Missing required columns in JSON: {missing}\"\n",
    "\n",
    "# Parse timestamp (MM-DD HH:MM)\n",
    "def parse_sensor_ts(s: str):\n",
    "    # Allow flexible formats\n",
    "    return pd.to_datetime(s, format=\"%m-%d %H:%M\", errors=\"coerce\")\n",
    "\n",
    "df[\"timestamp_dt\"] = df[\"timestamp\"].apply(parse_sensor_ts)\n",
    "assert df[\"timestamp_dt\"].notna().all(), \"Some timestamps failed to parse. Check format 'MM-DD HH:MM'.\"\n",
    "\n",
    "# Derive helpers: month-day key and minute-of-day\n",
    "df[\"md_key\"] = df[\"timestamp_dt\"].dt.strftime(\"%m-%d\")\n",
    "df[\"minute_of_day\"] = df[\"timestamp_dt\"].dt.hour * 60 + df[\"timestamp_dt\"].dt.minute\n",
    "\n",
    "# Validate condition labels (cond_output)\n",
    "unique_cond = sorted(df[\"label\"].astype(str).unique().tolist())\n",
    "unexpected = [u for u in unique_cond if u not in COND_LABELS_EXPECTED]\n",
    "if unexpected:\n",
    "    print(\"Warning: Found unexpected condition labels:\", unexpected)\n",
    "    # Merge into expected list deterministically to index everything\n",
    "    cond_labels = sorted(set(COND_LABELS_EXPECTED + unique_cond))\n",
    "else:\n",
    "    cond_labels = COND_LABELS_EXPECTED.copy()\n",
    "\n",
    "cond_label_to_idx = {c:i for i,c in enumerate(cond_labels)}\n",
    "cond_idx_to_label = {i:c for c,i in cond_label_to_idx.items()}\n",
    "\n",
    "print(\"Condition labels mapping:\", cond_label_to_idx)\n",
    "\n",
    "# Scale numerical features\n",
    "num_cols = [\"temp\", \"moist\", \"brightness\", \"green\"]\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols].values.astype(np.float32))\n",
    "\n",
    "print(\"Loaded sensor rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89002309",
   "metadata": {},
   "source": [
    "## 4) Load Images, Parse Filenames, Build Image Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ef8e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images: 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>img_label</th>\n",
       "      <th>md_key</th>\n",
       "      <th>minute_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AWSimages-labeled\\bad_h.07-15_21-20.jpg</td>\n",
       "      <td>bad_h</td>\n",
       "      <td>07-15</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AWSimages-labeled\\bad_h.07-16_06-10.jpg</td>\n",
       "      <td>bad_h</td>\n",
       "      <td>07-16</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AWSimages-labeled\\bad_h.07-16_10-10.jpg</td>\n",
       "      <td>bad_h</td>\n",
       "      <td>07-16</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWSimages-labeled\\bad_h.07-16_14-10.jpg</td>\n",
       "      <td>bad_h</td>\n",
       "      <td>07-16</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWSimages-labeled\\bad_h.07-16_21-20.jpg</td>\n",
       "      <td>bad_h</td>\n",
       "      <td>07-16</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filepath img_label md_key  minute_of_day\n",
       "0  AWSimages-labeled\\bad_h.07-15_21-20.jpg     bad_h  07-15           1280\n",
       "1  AWSimages-labeled\\bad_h.07-16_06-10.jpg     bad_h  07-16            370\n",
       "2  AWSimages-labeled\\bad_h.07-16_10-10.jpg     bad_h  07-16            610\n",
       "3  AWSimages-labeled\\bad_h.07-16_14-10.jpg     bad_h  07-16            850\n",
       "4  AWSimages-labeled\\bad_h.07-16_21-20.jpg     bad_h  07-16           1280"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "assert IMAGES_DIR.exists(), f\"Missing image directory: {IMAGES_DIR}\"\n",
    "\n",
    "image_records = []\n",
    "img_pattern = re.compile(r'^(good_h|bad_h)\\.(\\d{2})-(\\d{2})_(\\d{2})-(\\d{2})', re.IGNORECASE)\n",
    "\n",
    "valid_exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "for root, _, files in os.walk(IMAGES_DIR):\n",
    "    for fname in files:\n",
    "        ext = Path(fname).suffix.lower()\n",
    "        if ext not in valid_exts:\n",
    "            continue\n",
    "        m = img_pattern.match(fname)\n",
    "        if not m:\n",
    "            # Skip files that don't conform to expected pattern\n",
    "            continue\n",
    "        label_raw, mm, dd, HH, MM = m.groups()\n",
    "        label = label_raw.lower()\n",
    "        mmdd = f\"{int(mm):02d}-{int(dd):02d}\"\n",
    "        minute_of_day = int(HH) * 60 + int(MM)\n",
    "        fpath = str(Path(root) / fname)\n",
    "        image_records.append({\n",
    "            \"filepath\": fpath,\n",
    "            \"img_label\": label,           # 'good_h' or 'bad_h'\n",
    "            \"md_key\": mmdd,               # month-day\n",
    "            \"minute_of_day\": minute_of_day\n",
    "        })\n",
    "\n",
    "img_df = pd.DataFrame(image_records)\n",
    "if img_df.empty:\n",
    "    print(\"No valid images found matching the expected pattern. Proceeding with zero-image tensors for all samples.\")\n",
    "else:\n",
    "    # Normalize label case and validate\n",
    "    img_df[\"img_label\"] = img_df[\"img_label\"].str.lower()\n",
    "    valid_img_labels = set(IMG_LABELS)\n",
    "    unexpected_img_labels = sorted(set(img_df[\"img_label\"]) - valid_img_labels)\n",
    "    assert not unexpected_img_labels, f\"Unexpected image labels: {unexpected_img_labels}\"\n",
    "    print(\"Loaded images:\", len(img_df))\n",
    "\n",
    "img_df.head() if not img_df.empty else img_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b2be7",
   "metadata": {},
   "source": [
    "## 5) Match Each Sensor Row to the Nearest Same-Day Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b368b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched images (some may be None if no same-day image existed).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>md_key</th>\n",
       "      <th>minute_of_day</th>\n",
       "      <th>matched_img_path</th>\n",
       "      <th>matched_img_label</th>\n",
       "      <th>time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07-14 21:45</td>\n",
       "      <td>07-14</td>\n",
       "      <td>1305</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-14_21-20.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07-15 05:45</td>\n",
       "      <td>07-15</td>\n",
       "      <td>345</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_06-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07-15 06:15</td>\n",
       "      <td>07-15</td>\n",
       "      <td>375</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_06-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-15 06:45</td>\n",
       "      <td>07-15</td>\n",
       "      <td>405</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_06-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07-15 07:15</td>\n",
       "      <td>07-15</td>\n",
       "      <td>435</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_06-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07-15 07:45</td>\n",
       "      <td>07-15</td>\n",
       "      <td>465</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_06-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07-15 08:15</td>\n",
       "      <td>07-15</td>\n",
       "      <td>495</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_10-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>07-15 08:45</td>\n",
       "      <td>07-15</td>\n",
       "      <td>525</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_10-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>07-15 09:15</td>\n",
       "      <td>07-15</td>\n",
       "      <td>555</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_10-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>07-15 09:45</td>\n",
       "      <td>07-15</td>\n",
       "      <td>585</td>\n",
       "      <td>AWSimages-labeled\\good_h.07-15_10-10.jpg</td>\n",
       "      <td>good_h</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp md_key  minute_of_day  \\\n",
       "0  07-14 21:45  07-14           1305   \n",
       "1  07-15 05:45  07-15            345   \n",
       "2  07-15 06:15  07-15            375   \n",
       "3  07-15 06:45  07-15            405   \n",
       "4  07-15 07:15  07-15            435   \n",
       "5  07-15 07:45  07-15            465   \n",
       "6  07-15 08:15  07-15            495   \n",
       "7  07-15 08:45  07-15            525   \n",
       "8  07-15 09:15  07-15            555   \n",
       "9  07-15 09:45  07-15            585   \n",
       "\n",
       "                           matched_img_path matched_img_label  time_diff  \n",
       "0  AWSimages-labeled\\good_h.07-14_21-20.jpg            good_h       25.0  \n",
       "1  AWSimages-labeled\\good_h.07-15_06-10.jpg            good_h       25.0  \n",
       "2  AWSimages-labeled\\good_h.07-15_06-10.jpg            good_h        5.0  \n",
       "3  AWSimages-labeled\\good_h.07-15_06-10.jpg            good_h       35.0  \n",
       "4  AWSimages-labeled\\good_h.07-15_06-10.jpg            good_h       65.0  \n",
       "5  AWSimages-labeled\\good_h.07-15_06-10.jpg            good_h       95.0  \n",
       "6  AWSimages-labeled\\good_h.07-15_10-10.jpg            good_h      115.0  \n",
       "7  AWSimages-labeled\\good_h.07-15_10-10.jpg            good_h       85.0  \n",
       "8  AWSimages-labeled\\good_h.07-15_10-10.jpg            good_h       55.0  \n",
       "9  AWSimages-labeled\\good_h.07-15_10-10.jpg            good_h       25.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# For each sensor row, find closest image (absolute minutes difference) on the same md_key.\n",
    "def find_closest_image(row, group):\n",
    "    # group is img_df subset for the same md_key\n",
    "    if group is None or group.empty:\n",
    "        return pd.Series({\"matched_img_path\": None, \"matched_img_label\": None, \"time_diff\": None})\n",
    "    diffs = np.abs(group[\"minute_of_day\"].values - row[\"minute_of_day\"])\n",
    "    idx = diffs.argmin()\n",
    "    best = group.iloc[idx]\n",
    "    return pd.Series({\"matched_img_path\": best[\"filepath\"], \"matched_img_label\": best[\"img_label\"], \"time_diff\": int(diffs[idx])})\n",
    "\n",
    "if img_df.empty:\n",
    "    match_cols = df.apply(lambda r: pd.Series({\"matched_img_path\": None, \"matched_img_label\": None, \"time_diff\": None}), axis=1)\n",
    "else:\n",
    "    # Pre-group images by md_key for efficiency\n",
    "    img_groups = {k: g.reset_index(drop=True) for k, g in img_df.groupby(\"md_key\")}\n",
    "    match_cols = df.apply(lambda r: find_closest_image(r, img_groups.get(r[\"md_key\"])), axis=1)\n",
    "\n",
    "df = pd.concat([df, match_cols], axis=1)\n",
    "print(\"Matched images (some may be None if no same-day image existed).\")\n",
    "df[[\"timestamp\", \"md_key\", \"minute_of_day\", \"matched_img_path\", \"matched_img_label\", \"time_diff\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169144ba",
   "metadata": {},
   "source": [
    "## 6) Prepare Tensors & Labels (Sensors + Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce524234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X_sensor: (552, 4)\n",
      "  X_image : (552, 224, 224, 3)\n",
      "  y_img   : (552,) | positives (has image): 496\n",
      "  y_cond  : (552,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sensor features\n",
    "X_sensor = df[[\"temp\", \"moist\", \"brightness\", \"green\"]].values.astype(np.float32)\n",
    "\n",
    "# Condition labels (cond_output), integers for SparseCategoricalCrossentropy\n",
    "y_cond = df[\"label\"].map(cond_label_to_idx).values.astype(np.int64)\n",
    "\n",
    "# Image labels (img_output): map to integers; if missing image, use placeholder 0 but weight=0\n",
    "img_label_to_idx = {lab:i for i, lab in enumerate(IMG_LABELS)}\n",
    "img_has = df[\"matched_img_label\"].notna().values\n",
    "y_img = np.where(img_has, df[\"matched_img_label\"].map(img_label_to_idx).fillna(0).values, 0).astype(np.int64)\n",
    "\n",
    "# Sample weights: missing images get weight 0 for the img_output head\n",
    "sw_img = img_has.astype(np.float32)  # 1.0 if have image, else 0.0\n",
    "sw_cond = np.ones_like(sw_img, dtype=np.float32)\n",
    "\n",
    "# Build image tensor array\n",
    "def load_image(path, size=(224,224)):\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im = im.convert(\"RGB\").resize(size, Image.BILINEAR)\n",
    "            arr = np.asarray(im, dtype=np.float32) / 255.0\n",
    "            return arr\n",
    "    except Exception as e:\n",
    "        # If loading fails, fall back to zero image and zero weight\n",
    "        return np.zeros((size[0], size[1], 3), dtype=np.float32)\n",
    "\n",
    "N = len(df)\n",
    "X_image = np.zeros((N, IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS), dtype=np.float32)\n",
    "if img_df.empty:\n",
    "    # All zeros already\n",
    "    pass\n",
    "else:\n",
    "    for i, p in enumerate(df[\"matched_img_path\"].values):\n",
    "        if isinstance(p, str) and Path(p).exists():\n",
    "            X_image[i] = load_image(p, IMG_SIZE)\n",
    "        else:\n",
    "            # Missing image: keep zeros, sample weight will mask loss\n",
    "            pass\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_sensor:\", X_sensor.shape)\n",
    "print(\"  X_image :\", X_image.shape)\n",
    "print(\"  y_img   :\", y_img.shape, \"| positives (has image):\", int(sw_img.sum()))\n",
    "print(\"  y_cond  :\", y_cond.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd5812",
   "metadata": {},
   "source": [
    "## 7) Chronological Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74432c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 386, Val: 83, Test: 83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train+val and test (15% test)\n",
    "X_image_trainval, X_image_test, X_sensor_trainval, X_sensor_test, \\\n",
    "    y_img_trainval, y_img_test, y_cond_trainval, y_cond_test, \\\n",
    "    sw_img_trainval, sw_img_test, sw_cond_trainval, sw_cond_test = train_test_split(\n",
    "        X_image, X_sensor, y_img, y_cond, sw_img, sw_cond,\n",
    "        test_size=0.15, random_state=42, stratify=y_cond\n",
    ")\n",
    "\n",
    "# Split trainval into train and val (so val ~15% of total)\n",
    "X_image_train, X_image_val, X_sensor_train, X_sensor_val, \\\n",
    "    y_img_train, y_img_val, y_cond_train, y_cond_val, \\\n",
    "    sw_img_train, sw_img_val, sw_cond_train, sw_cond_val = train_test_split(\n",
    "        X_image_trainval, X_sensor_trainval,\n",
    "        y_img_trainval, y_cond_trainval,\n",
    "        sw_img_trainval, sw_cond_trainval,\n",
    "        test_size=0.176, random_state=42, stratify=y_cond_trainval\n",
    ")\n",
    "print(f\"Train: {len(X_image_train)}, Val: {len(X_image_val)}, Test: {len(X_image_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ff1ee",
   "metadata": {},
   "source": [
    "## 8) Build Dual-Input, Dual-Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7e58f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sensor_input (InputLayer)      [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " image_input (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           160         ['sensor_input[0][0]']           \n",
      "                                                                                                  \n",
      " augmentation (Sequential)      (None, 224, 224, 3)  0           ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " mobilenetv2_1.00_224 (Function  (None, 1280)        2257984     ['augmentation[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           528         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1296)         0           ['mobilenetv2_1.00_224[0][0]',   \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           83008       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " img_output (Dense)             (None, 2)            130         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " cond_output (Dense)            (None, 8)            520         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,342,330\n",
      "Trainable params: 84,346\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Image branch\n",
    "img_input = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS), name=\"image_input\")\n",
    "\n",
    "data_augment = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05)\n",
    "], name=\"augmentation\")\n",
    "\n",
    "x_img = data_augment(img_input)\n",
    "base = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE[0], IMG_SIZE[1], IMG_CHANNELS), pooling=\"avg\")\n",
    "base.trainable = False\n",
    "x_img = base(x_img)\n",
    "\n",
    "# Sensor branch\n",
    "sensor_input = layers.Input(shape=(4,), name=\"sensor_input\")\n",
    "x_s = layers.Dense(32, activation=\"relu\")(sensor_input)\n",
    "x_s = layers.Dropout(0.3)(x_s)\n",
    "x_s = layers.Dense(16, activation=\"relu\")(x_s)\n",
    "\n",
    "# Merge\n",
    "x = layers.Concatenate()([x_img, x_s])\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "# Heads\n",
    "img_output = layers.Dense(2, activation=\"softmax\", name=\"img_output\")(x)\n",
    "cond_output = layers.Dense(len(cond_labels), activation=\"softmax\", name=\"cond_output\")(x)\n",
    "\n",
    "model = models.Model(inputs=[img_input, sensor_input], outputs=[img_output, cond_output])\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss={\n",
    "        \"img_output\": losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        \"cond_output\": losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    },\n",
    "    metrics={\"img_output\": [\"accuracy\"], \"cond_output\": [\"accuracy\"]},\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1711a4a",
   "metadata": {},
   "source": [
    "## 9) Train with EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e778129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.2077 - img_output_loss: 0.7643 - cond_output_loss: 1.4434 - img_output_accuracy: 0.5648 - cond_output_accuracy: 0.4845WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 75s 3s/step - loss: 2.2077 - img_output_loss: 0.7643 - cond_output_loss: 1.4434 - img_output_accuracy: 0.5648 - cond_output_accuracy: 0.4845 - val_loss: 1.2675 - val_img_output_loss: 0.4307 - val_cond_output_loss: 0.8367 - val_img_output_accuracy: 0.8072 - val_cond_output_accuracy: 0.7470\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5238 - img_output_loss: 0.4800 - cond_output_loss: 1.0438 - img_output_accuracy: 0.6995 - cond_output_accuracy: 0.6399WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 37s 3s/step - loss: 1.5238 - img_output_loss: 0.4800 - cond_output_loss: 1.0438 - img_output_accuracy: 0.6995 - cond_output_accuracy: 0.6399 - val_loss: 1.0255 - val_img_output_loss: 0.3722 - val_cond_output_loss: 0.6533 - val_img_output_accuracy: 0.8554 - val_cond_output_accuracy: 0.8072\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1997 - img_output_loss: 0.4316 - cond_output_loss: 0.7680 - img_output_accuracy: 0.7254 - cond_output_accuracy: 0.7642WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 30s 2s/step - loss: 1.1997 - img_output_loss: 0.4316 - cond_output_loss: 0.7680 - img_output_accuracy: 0.7254 - cond_output_accuracy: 0.7642 - val_loss: 0.8601 - val_img_output_loss: 0.3135 - val_cond_output_loss: 0.5466 - val_img_output_accuracy: 0.8675 - val_cond_output_accuracy: 0.8434\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9548 - img_output_loss: 0.3585 - cond_output_loss: 0.5963 - img_output_accuracy: 0.8005 - cond_output_accuracy: 0.7953WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 24s 2s/step - loss: 0.9548 - img_output_loss: 0.3585 - cond_output_loss: 0.5963 - img_output_accuracy: 0.8005 - cond_output_accuracy: 0.7953 - val_loss: 0.7129 - val_img_output_loss: 0.2903 - val_cond_output_loss: 0.4226 - val_img_output_accuracy: 0.9277 - val_cond_output_accuracy: 0.8675\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8402 - img_output_loss: 0.3407 - cond_output_loss: 0.4995 - img_output_accuracy: 0.8083 - cond_output_accuracy: 0.8316WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 20s 2s/step - loss: 0.8402 - img_output_loss: 0.3407 - cond_output_loss: 0.4995 - img_output_accuracy: 0.8083 - cond_output_accuracy: 0.8316 - val_loss: 0.7132 - val_img_output_loss: 0.3216 - val_cond_output_loss: 0.3916 - val_img_output_accuracy: 0.8554 - val_cond_output_accuracy: 0.8795\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7563 - img_output_loss: 0.2663 - cond_output_loss: 0.4900 - img_output_accuracy: 0.8731 - cond_output_accuracy: 0.8575WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 20s 2s/step - loss: 0.7563 - img_output_loss: 0.2663 - cond_output_loss: 0.4900 - img_output_accuracy: 0.8731 - cond_output_accuracy: 0.8575 - val_loss: 0.5684 - val_img_output_loss: 0.1972 - val_cond_output_loss: 0.3712 - val_img_output_accuracy: 0.9518 - val_cond_output_accuracy: 0.8675\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6902 - img_output_loss: 0.2608 - cond_output_loss: 0.4293 - img_output_accuracy: 0.8420 - cond_output_accuracy: 0.8653WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 28s 2s/step - loss: 0.6902 - img_output_loss: 0.2608 - cond_output_loss: 0.4293 - img_output_accuracy: 0.8420 - cond_output_accuracy: 0.8653 - val_loss: 0.5271 - val_img_output_loss: 0.1848 - val_cond_output_loss: 0.3424 - val_img_output_accuracy: 0.9398 - val_cond_output_accuracy: 0.8916\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6025 - img_output_loss: 0.2564 - cond_output_loss: 0.3462 - img_output_accuracy: 0.8653 - cond_output_accuracy: 0.9041WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 28s 2s/step - loss: 0.6025 - img_output_loss: 0.2564 - cond_output_loss: 0.3462 - img_output_accuracy: 0.8653 - cond_output_accuracy: 0.9041 - val_loss: 0.5563 - val_img_output_loss: 0.2399 - val_cond_output_loss: 0.3164 - val_img_output_accuracy: 0.8916 - val_cond_output_accuracy: 0.9157\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5494 - img_output_loss: 0.1981 - cond_output_loss: 0.3513 - img_output_accuracy: 0.8912 - cond_output_accuracy: 0.8964WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 29s 2s/step - loss: 0.5494 - img_output_loss: 0.1981 - cond_output_loss: 0.3513 - img_output_accuracy: 0.8912 - cond_output_accuracy: 0.8964 - val_loss: 0.4499 - val_img_output_loss: 0.1677 - val_cond_output_loss: 0.2822 - val_img_output_accuracy: 0.9518 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4407 - img_output_loss: 0.1382 - cond_output_loss: 0.3025 - img_output_accuracy: 0.9301 - cond_output_accuracy: 0.9223WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 36s 3s/step - loss: 0.4407 - img_output_loss: 0.1382 - cond_output_loss: 0.3025 - img_output_accuracy: 0.9301 - cond_output_accuracy: 0.9223 - val_loss: 0.4257 - val_img_output_loss: 0.1534 - val_cond_output_loss: 0.2722 - val_img_output_accuracy: 0.9759 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4634 - img_output_loss: 0.1457 - cond_output_loss: 0.3177 - img_output_accuracy: 0.9249 - cond_output_accuracy: 0.9041WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 32s 3s/step - loss: 0.4634 - img_output_loss: 0.1457 - cond_output_loss: 0.3177 - img_output_accuracy: 0.9249 - cond_output_accuracy: 0.9041 - val_loss: 0.3951 - val_img_output_loss: 0.1296 - val_cond_output_loss: 0.2655 - val_img_output_accuracy: 0.9880 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3934 - img_output_loss: 0.1334 - cond_output_loss: 0.2599 - img_output_accuracy: 0.9145 - cond_output_accuracy: 0.9223WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 36s 3s/step - loss: 0.3934 - img_output_loss: 0.1334 - cond_output_loss: 0.2599 - img_output_accuracy: 0.9145 - cond_output_accuracy: 0.9223 - val_loss: 0.3772 - val_img_output_loss: 0.1137 - val_cond_output_loss: 0.2636 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3972 - img_output_loss: 0.1125 - cond_output_loss: 0.2847 - img_output_accuracy: 0.9301 - cond_output_accuracy: 0.9171WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 30s 2s/step - loss: 0.3972 - img_output_loss: 0.1125 - cond_output_loss: 0.2847 - img_output_accuracy: 0.9301 - cond_output_accuracy: 0.9171 - val_loss: 0.3740 - val_img_output_loss: 0.1330 - val_cond_output_loss: 0.2410 - val_img_output_accuracy: 0.9880 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3739 - img_output_loss: 0.1017 - cond_output_loss: 0.2722 - img_output_accuracy: 0.9430 - cond_output_accuracy: 0.9249WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 27s 2s/step - loss: 0.3739 - img_output_loss: 0.1017 - cond_output_loss: 0.2722 - img_output_accuracy: 0.9430 - cond_output_accuracy: 0.9249 - val_loss: 0.3445 - val_img_output_loss: 0.0929 - val_cond_output_loss: 0.2515 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3517 - img_output_loss: 0.0819 - cond_output_loss: 0.2698 - img_output_accuracy: 0.9611 - cond_output_accuracy: 0.9171WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 27s 2s/step - loss: 0.3517 - img_output_loss: 0.0819 - cond_output_loss: 0.2698 - img_output_accuracy: 0.9611 - cond_output_accuracy: 0.9171 - val_loss: 0.3061 - val_img_output_loss: 0.0729 - val_cond_output_loss: 0.2332 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9518\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3619 - img_output_loss: 0.0999 - cond_output_loss: 0.2620 - img_output_accuracy: 0.9534 - cond_output_accuracy: 0.9301WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 25s 2s/step - loss: 0.3619 - img_output_loss: 0.0999 - cond_output_loss: 0.2620 - img_output_accuracy: 0.9534 - cond_output_accuracy: 0.9301 - val_loss: 0.2954 - val_img_output_loss: 0.0777 - val_cond_output_loss: 0.2178 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3080 - img_output_loss: 0.0751 - cond_output_loss: 0.2329 - img_output_accuracy: 0.9560 - cond_output_accuracy: 0.9301WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 27s 2s/step - loss: 0.3080 - img_output_loss: 0.0751 - cond_output_loss: 0.2329 - img_output_accuracy: 0.9560 - cond_output_accuracy: 0.9301 - val_loss: 0.3213 - val_img_output_loss: 0.0804 - val_cond_output_loss: 0.2408 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2948 - img_output_loss: 0.0701 - cond_output_loss: 0.2247 - img_output_accuracy: 0.9689 - cond_output_accuracy: 0.9275WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 27s 2s/step - loss: 0.2948 - img_output_loss: 0.0701 - cond_output_loss: 0.2247 - img_output_accuracy: 0.9689 - cond_output_accuracy: 0.9275 - val_loss: 0.2748 - val_img_output_loss: 0.0598 - val_cond_output_loss: 0.2150 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9518\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2963 - img_output_loss: 0.0742 - cond_output_loss: 0.2221 - img_output_accuracy: 0.9585 - cond_output_accuracy: 0.9378WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 27s 2s/step - loss: 0.2963 - img_output_loss: 0.0742 - cond_output_loss: 0.2221 - img_output_accuracy: 0.9585 - cond_output_accuracy: 0.9378 - val_loss: 0.3101 - val_img_output_loss: 0.0560 - val_cond_output_loss: 0.2542 - val_img_output_accuracy: 0.9759 - val_cond_output_accuracy: 0.9518\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3314 - img_output_loss: 0.0924 - cond_output_loss: 0.2390 - img_output_accuracy: 0.9404 - cond_output_accuracy: 0.9301WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 21s 2s/step - loss: 0.3314 - img_output_loss: 0.0924 - cond_output_loss: 0.2390 - img_output_accuracy: 0.9404 - cond_output_accuracy: 0.9301 - val_loss: 0.3027 - val_img_output_loss: 0.0722 - val_cond_output_loss: 0.2304 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2822 - img_output_loss: 0.0755 - cond_output_loss: 0.2067 - img_output_accuracy: 0.9611 - cond_output_accuracy: 0.9223WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 21s 2s/step - loss: 0.2822 - img_output_loss: 0.0755 - cond_output_loss: 0.2067 - img_output_accuracy: 0.9611 - cond_output_accuracy: 0.9223 - val_loss: 0.2753 - val_img_output_loss: 0.0621 - val_cond_output_loss: 0.2132 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3055 - img_output_loss: 0.0837 - cond_output_loss: 0.2218 - img_output_accuracy: 0.9637 - cond_output_accuracy: 0.9326WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "13/13 [==============================] - 24s 2s/step - loss: 0.3055 - img_output_loss: 0.0837 - cond_output_loss: 0.2218 - img_output_accuracy: 0.9637 - cond_output_accuracy: 0.9326 - val_loss: 0.2885 - val_img_output_loss: 0.0541 - val_cond_output_loss: 0.2344 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2534 - img_output_loss: 0.0714 - cond_output_loss: 0.1820 - img_output_accuracy: 0.9585 - cond_output_accuracy: 0.9378WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "13/13 [==============================] - 28s 2s/step - loss: 0.2534 - img_output_loss: 0.0714 - cond_output_loss: 0.1820 - img_output_accuracy: 0.9585 - cond_output_accuracy: 0.9378 - val_loss: 0.2644 - val_img_output_loss: 0.0448 - val_cond_output_loss: 0.2196 - val_img_output_accuracy: 1.0000 - val_cond_output_accuracy: 0.9398\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = callbacks.EarlyStopping(\n",
    "    monitor=\"val_cond_output_accuracy\",\n",
    "    mode=\"max\",   # maximize this metric\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the dual-output model\n",
    "history = model.fit(\n",
    "    x={\n",
    "        \"image_input\": X_image_train,\n",
    "        \"sensor_input\": X_sensor_train\n",
    "    },\n",
    "    y=[y_img_train, y_cond_train],   # Outputs\n",
    "    sample_weight=[sw_img_train, sw_cond_train],  # Sample weights\n",
    "    validation_data=(\n",
    "        {\n",
    "            \"image_input\": X_image_val,\n",
    "            \"sensor_input\": X_sensor_val\n",
    "        },\n",
    "        [y_img_val, y_cond_val],     # Validation outputs\n",
    "        [sw_img_val, sw_cond_val],   # Validation weights\n",
    "    ),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    callbacks=[es],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff3889",
   "metadata": {},
   "source": [
    "## 10) Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb8453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 24s 1s/step\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "Image branch accuracy: 1.0\n",
      "Condition branch accuracy: 0.963855421686747\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_probs_img, y_pred_probs_cond = model.predict(\n",
    "    {\"image_input\": X_image_test, \"sensor_input\": X_sensor_test}, verbose=0\n",
    ")\n",
    "\n",
    "y_pred_probs_img = model.predict([X_image_test, X_sensor_test])[0]\n",
    "y_pred_probs_cond = model.predict([X_image_test, X_sensor_test])[1]\n",
    "\n",
    "y_pred_img = np.argmax(y_pred_probs_img, axis=1)\n",
    "y_pred_cond = np.argmax(y_pred_probs_cond, axis=1)\n",
    "\n",
    "\n",
    "# Accuracies\n",
    "acc_img = accuracy_score(y_img_test, y_pred_img)\n",
    "acc_cond = accuracy_score(y_cond_test, y_pred_cond)\n",
    "\n",
    "print(\"Image branch accuracy:\", acc_img)\n",
    "print(\"Condition branch accuracy:\", acc_cond)\n",
    "\n",
    "\n",
    "# Confusion matrices\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_img_test, y_pred_img, ax=ax[0],\n",
    "    cmap=\"Blues\", values_format=\"d\", display_labels=IMG_LABELS\n",
    ")\n",
    "ax[0].set_title(\"Confusion Matrix - Image Output (Test)\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_cond_test, y_pred_cond, ax=ax[1],\n",
    "    cmap=\"Blues\", values_format=\"d\", display_labels=COND_LABELS_EXPECTED\n",
    ")\n",
    "ax[1].set_title(\"Confusion Matrix - Sensor Output (Test)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50590006",
   "metadata": {},
   "source": [
    "## 11) Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46db5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to C:\\Users\\X415\\Downloads\\sensor_image_model.h5\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = Path(\"sensor_image_model.h5\")\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"Saved model to {MODEL_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0997491",
   "metadata": {},
   "source": [
    "## Optional for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image branch prediction: good_h\n",
      "Sensor branch prediction: Healthy\n"
     ]
    }
   ],
   "source": [
    "# ==== Manual test input ====\n",
    "import numpy as np\n",
    "\n",
    "# Replace with your own sensor data (must match input shape)\n",
    "test_sensor = np.array([[0.5, 0.2, 0.8, 2]])  \n",
    "\n",
    "# Replace with your own image data (normalized, shape must match)\n",
    "test_image = np.random.rand(1, *X_image.shape[1:])  \n",
    "\n",
    "# Predict\n",
    "pred_img, pred_cond = model.predict(\n",
    "    {\"image_input\": test_image, \"sensor_input\": test_sensor}, verbose=0\n",
    ")\n",
    "\n",
    "# Get indices\n",
    "pred_img_idx = np.argmax(pred_img, axis=1)[0]\n",
    "pred_cond_idx = np.argmax(pred_cond, axis=1)[0]\n",
    "\n",
    "# Map to class names\n",
    "print(\"Image branch prediction:\", IMG_LABELS[pred_img_idx])\n",
    "print(\"Sensor branch prediction:\", COND_LABELS_EXPECTED[pred_cond_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38e5d0",
   "metadata": {},
   "source": [
    "##12) Convert to ONNX for export (separate kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874dc096",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': False, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\ops\\operation.py:255\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\depthwise_conv2d.py:120\u001b[39m, in \u001b[36mDepthwiseConv2D.__init__\u001b[39m\u001b[34m(self, kernel_size, strides, padding, depth_multiplier, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    103\u001b[39m     kernel_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    118\u001b[39m     **kwargs,\n\u001b[32m    119\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdepth_multiplier\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepth_multiplier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdilation_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdilation_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdepthwise_initializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepthwise_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_initializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdepthwise_regularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepthwise_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdepthwise_constraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepthwise_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_constraint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_depthwise_conv.py:106\u001b[39m, in \u001b[36mBaseDepthwiseConv.__init__\u001b[39m\u001b[34m(self, rank, depth_multiplier, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, trainable, name, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     86\u001b[39m     rank,\n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m     **kwargs,\n\u001b[32m    105\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregularizers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mself\u001b[39m.rank = rank\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:291\u001b[39m, in \u001b[36mLayer.__init__\u001b[39m\u001b[34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    292\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnrecognized keyword arguments \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    293\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    294\u001b[39m     )\n\u001b[32m    296\u001b[39m \u001b[38;5;28mself\u001b[39m._path = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load .h5\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC:/Users/X415/Downloads/sensor_image_model.h5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Save as TensorFlow SavedModel directory\u001b[39;00m\n\u001b[32m      7\u001b[39m model.save(\u001b[33m'\u001b[39m\u001b[33mC:/Users/Hercu/Downloads/saved_model_dir\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:196\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib.load_model(\n\u001b[32m    190\u001b[39m         filepath,\n\u001b[32m    191\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    193\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:137\u001b[39m, in \u001b[36mload_model_from_hdf5\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    135\u001b[39m safe_mode_scope = serialization_lib.SafeModeScope(safe_mode)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m legacy_scope, safe_mode_scope:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     model = \u001b[43msaving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[32m    142\u001b[39m     load_weights_from_hdf5_group(f[\u001b[33m\"\u001b[39m\u001b[33mmodel_weights\u001b[39m\u001b[33m\"\u001b[39m], model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:83\u001b[39m, in \u001b[36mmodel_from_config\u001b[39m\u001b[34m(config, custom_objects)\u001b[39m\n\u001b[32m     80\u001b[39m         function_dict[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mclosure\u001b[39m\u001b[33m\"\u001b[39m] = function_config[\u001b[32m2\u001b[39m]\n\u001b[32m     81\u001b[39m         config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m] = function_dict\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:488\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[39m\n\u001b[32m    485\u001b[39m custom_objects = custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcustom_objects\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec.args:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     deserialized_obj = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mobject_registration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration.CustomObjectScope(custom_objects):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\models\\model.py:660\u001b[39m, in \u001b[36mModel.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[32m    656\u001b[39m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[32m    657\u001b[39m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[32m    665\u001b[39m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\models\\functional.py:558\u001b[39m, in \u001b[36mfunctional_from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[33m\"\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\models\\functional.py:521\u001b[39m, in \u001b[36mfunctional_from_config.<locals>.process_layer\u001b[39m\u001b[34m(layer_data)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     layer = \u001b[43msaving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    525\u001b[39m     layer = serialization_lib.deserialize_keras_object(\n\u001b[32m    526\u001b[39m         layer_data, custom_objects=custom_objects\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:83\u001b[39m, in \u001b[36mmodel_from_config\u001b[39m\u001b[34m(config, custom_objects)\u001b[39m\n\u001b[32m     80\u001b[39m         function_dict[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mclosure\u001b[39m\u001b[33m\"\u001b[39m] = function_config[\u001b[32m2\u001b[39m]\n\u001b[32m     81\u001b[39m         config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m] = function_dict\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:488\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[39m\n\u001b[32m    485\u001b[39m custom_objects = custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcustom_objects\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec.args:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     deserialized_obj = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mobject_registration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration.CustomObjectScope(custom_objects):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\models\\model.py:660\u001b[39m, in \u001b[36mModel.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[32m    656\u001b[39m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[32m    657\u001b[39m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[32m    665\u001b[39m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\models\\functional.py:558\u001b[39m, in \u001b[36mfunctional_from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[33m\"\u001b[39m\u001b[33mlayers\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\models\\functional.py:521\u001b[39m, in \u001b[36mfunctional_from_config.<locals>.process_layer\u001b[39m\u001b[34m(layer_data)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     layer = \u001b[43msaving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    525\u001b[39m     layer = serialization_lib.deserialize_keras_object(\n\u001b[32m    526\u001b[39m         layer_data, custom_objects=custom_objects\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:83\u001b[39m, in \u001b[36mmodel_from_config\u001b[39m\u001b[34m(config, custom_objects)\u001b[39m\n\u001b[32m     80\u001b[39m         function_dict[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mclosure\u001b[39m\u001b[33m\"\u001b[39m] = function_config[\u001b[32m2\u001b[39m]\n\u001b[32m     81\u001b[39m         config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m] = function_dict\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:497\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[39m\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    496\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m object_registration.CustomObjectScope(custom_objects):\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m             deserialized_obj = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    499\u001b[39m     \u001b[38;5;66;03m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[32m    500\u001b[39m     \u001b[38;5;66;03m# in this case by convention `config` holds\u001b[39;00m\n\u001b[32m    501\u001b[39m     \u001b[38;5;66;03m# the kwargs of the function.\u001b[39;00m\n\u001b[32m    502\u001b[39m     custom_objects = custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\X415\\anaconda3_1\\envs\\cpu_env\\Lib\\site-packages\\keras\\src\\ops\\operation.py:257\u001b[39m, in \u001b[36mOperation.from_config\u001b[39m\u001b[34m(cls, config)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**config)\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    258\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError when deserializing class \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    259\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': False, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load .h5\n",
    "model = tf.keras.models.load_model('C:/Users/X415/Downloads/sensor_image_model.h5')\n",
    "\n",
    "# Save as TensorFlow SavedModel directory\n",
    "model.save('C:/Users/Hercu/Downloads/saved_model_dir')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffb850",
   "metadata": {},
   "source": [
    "##13) Convert to ONNX for export (separate kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in cmd using python 3.10\n",
    "python -m tf2onnx.convert --saved-model C:/Users/X415/Downloads/saved_model_dir --output model.onnx --opset 13"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cpu_env)",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
